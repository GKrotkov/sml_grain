---
title: "EDA"
author: "Elizabeth Ho"
output: pdf_document
---

# Load in data, basic exploration of data
```{r}
# Load in the data
train <- read.csv("data/train_data.csv")
```

```{r}
full_model <- lm(Y ~ ., data = train)
summary(full_model)
```

```{r}
correlation_matrix <- cor(train[, -which(names(train) == "Y")])
correlation_matrix
```

```{r}
library(corrplot)
# Circles correlation plot
corrplot(cor(train), method = "circle",
        tl.pos = "n", mar = c(2, 1, 3, 1)) 
```

```{r, fig.width=19, fig.height=9}
# Visualization of correlation matrix
corrplot.mixed(cor(train),
               lower = "number", 
               upper = "circle",
               tl.col = "black")
```
## NOTES
- Only use area, not perimeter, axis length, etc.

```{r}
# Check for multicollinearity
library(car)
vif_values <- vif(full_model)
vif_values
```

# Splitting data into training and validation

```{r}
# Splitting the data into training and validation sets
set.seed(1234)
index <- sample(1:nrow(train), round(0.8 * nrow(train)))
train_set <- train[index, ]
validation_set <- train[-index, ]
```

# LASSO
Do we need to standardize features?
```{r}
# NOTE: I did NOT standardize features; here is the code if we wanted to do so
# Standardize the features
standardized_train <- scale(train)
standardized_train <- as.data.frame(standardized_train)

# Fit the Lasso model on the standardized data
lasso_model_standardized <- cv.glmnet(as.matrix(standardized_train), train$Y, alpha = 1)
```

```{r, warning=FALSE, message=FALSE}
# Use Lasso?
library(glmnet)
x_train <- model.matrix(Y ~ . - 1, data = train_set) # -1 to exclude intercept
y_train <- train_set$Y
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)
plot(lasso_model)

# Predictions for the validation set
x_validation <- model.matrix(Y ~ . - 1, data = validation_set)
predictions <- predict(lasso_model, s = "lambda.min", newx = x_validation)
```

```{r}
# Extract coefficients of the model at lambda.min
lasso_coefficients <- coef(lasso_model, s = "lambda.min")

# Non-zero coefficients
print(round(lasso_coefficients[lasso_coefficients != 0], 6))
```

## Coefficients with variable names
```{r}
lasso_coefficients <- coef(lasso_model, s = "lambda.min")
variable_names <- colnames(x_train)
coef_w_names <- setNames(lasso_coefficients[-1], variable_names)
print(round(coef_w_names[coef_w_names != 0], 6))
```

Less significant variables:
- Area
- Perimeter
- Major Axis Length
- Convex Area
- EquivDiameter (?)

```{r}
# Predict using the validation set
predictions <- predict(lasso_model, s = "lambda.min", newx = x_validation)

# MSE on the validation set
mse <- mean((validation_set$Y - predictions)^2)
mse
```

# Ridge

```{r}
ridge_model <- cv.glmnet(x_train, y_train, alpha = 0)

# CV curve
plot(ridge_model)
```

```{r}
# Predictions for the validation set
ridge_predictions <- predict(ridge_model, s = "lambda.min", newx = x_validation)

# Extract coefficients of the Ridge model at lambda.min
ridge_coefficients <- coef(ridge_model, s = "lambda.min")

# Non-zero coefficients
print(round(ridge_coefficients, 6))
```

```{r}
# MSE for the validation set 
ridge_mse <- mean((validation_set$Y - ridge_predictions)^2)
ridge_mse
```

